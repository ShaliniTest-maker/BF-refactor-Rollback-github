# Tox Configuration for Flask Migration Integration Testing
# =========================================================
# 
# This tox configuration orchestrates multi-environment integration testing
# across different Python versions and dependency configurations for the
# comprehensive Flask 3.1.1 migration validation project.
# 
# Key Features:
# - tox 4.26.0 multi-environment testing orchestration per Section 4.7.2
# - Python 3.13.3 runtime validation per technical specification
# - Flask 3.1.1 compatibility validation with comprehensive coverage
# - Virtual environment isolation for reproducible test execution
# - pytest-flask 1.3.0 integration for Flask-specific testing capabilities
# - pytest-benchmark 5.1.0 for performance comparison against Node.js baseline
# - Automated CI/CD pipeline integration for migration validation
# - Parallel environment provisioning for comprehensive test coverage
# 
# Technical Specification References:
# - Section 4.7.2: Comparative Testing Process with tox 4.26.0
# - Section 4.7.1: Functionality Parity Validation with pytest-flask 1.3.0
# - Section 3.2: Flask 3.1.1 and ecosystem compatibility requirements
# - Section 2.4: Performance and scalability validation requirements

[tox]
# ===================================================================
# GLOBAL TOX CONFIGURATION
# ===================================================================

# Minimum tox version required per Section 4.7.2 technical specification
minversion = 4.26.0

# Python versions for comprehensive multi-environment testing
# Primary focus on Python 3.13.3 per migration requirements
envlist = 
    py313-integration
    py313-performance
    py313-comparative
    py313-coverage
    py313-flask311
    py313-sqlalchemy
    py313-parallel
    lint
    docs

# Skip missing Python interpreters to allow selective environment testing
skip_missing_interpreters = true

# Parallel execution for improved test performance
# Enables concurrent environment provisioning per Section 4.7.2
parallel_show_output = true

# Isolated build to ensure reproducible test environments
isolated_build = true

# Default test runner configuration
testpaths = tests/integration

# ===================================================================
# DEFAULT TEST ENVIRONMENT CONFIGURATION
# ===================================================================

[testenv]
# Base Python interpreter version per technical specification
basepython = python3.13

# Working directory for all test environments
changedir = {toxinidir}

# Core dependencies installation from requirements files
deps = 
    -r{toxinidir}/tests/integration/requirements-test.txt

# Environment variables for Flask testing configuration
setenv =
    # Flask application configuration for testing
    FLASK_ENV = testing
    FLASK_APP = src.app:create_app
    FLASK_DEBUG = 0
    
    # Database configuration for testing isolation
    DATABASE_URL = sqlite:///:memory:
    TEST_DATABASE_URL = sqlite:///:memory:
    
    # Authentication testing configuration
    SECRET_KEY = test-secret-key-for-integration-testing
    AUTH0_DOMAIN = test-auth0-domain.auth0.com
    AUTH0_CLIENT_ID = test-client-id
    AUTH0_CLIENT_SECRET = test-client-secret
    
    # Testing framework configuration
    PYTEST_CURRENT_TEST = {envname}
    TOX_ENV_NAME = {envname}
    
    # Performance testing configuration
    BENCHMARK_ONLY = false
    BENCHMARK_SKIP = false
    
    # Coverage configuration
    COVERAGE_PROCESS_START = {toxinidir}/.coveragerc

# Default test command using pytest with Flask integration
commands = 
    pytest {posargs:tests/integration} \
        --verbose \
        --tb=short \
        --strict-markers \
        --strict-config \
        --junit-xml={toxinidir}/test-results/{envname}/junit.xml

# Recreate virtual environments for clean testing
recreate = false

# ===================================================================
# INTEGRATION TESTING ENVIRONMENT
# ===================================================================

[testenv:py313-integration]
# Primary integration testing environment for Flask 3.1.1 migration validation
# Comprehensive Flask application testing with pytest-flask 1.3.0 per Section 4.7.1

description = Flask 3.1.1 integration testing with pytest-flask 1.3.0

deps = 
    {[testenv]deps}

setenv = 
    {[testenv]setenv}
    # Integration-specific configuration
    FLASK_TESTING = true
    INTEGRATION_TEST_MODE = true
    TEST_ENVIRONMENT = integration

commands = 
    # Flask application factory validation
    pytest tests/integration/test_flask_migration_parity.py \
        --verbose \
        --tb=long \
        --durations=20 \
        --junit-xml={toxinidir}/test-results/integration/junit.xml \
        --html={toxinidir}/test-results/integration/report.html \
        --self-contained-html \
        -m "not performance and not benchmark" \
        {posargs}
    
    # API endpoint validation with Flask blueprints
    pytest tests/integration/api/ \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/integration-api/junit.xml \
        {posargs}
    
    # Database integration testing with Flask-SQLAlchemy
    pytest tests/integration/database/ \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/integration-db/junit.xml \
        {posargs}

# ===================================================================
# PERFORMANCE TESTING ENVIRONMENT
# ===================================================================

[testenv:py313-performance]
# Performance benchmarking environment with pytest-benchmark 5.1.0
# Validates Flask implementation performance against Node.js baseline per Section 4.7.1

description = Performance benchmarking with pytest-benchmark 5.1.0

deps = 
    {[testenv]deps}
    # Additional performance testing dependencies
    memory-profiler>=0.61.0
    psutil>=6.1.0

setenv = 
    {[testenv]setenv}
    # Performance testing specific configuration
    BENCHMARK_ONLY = true
    BENCHMARK_SKIP = false
    PERFORMANCE_TEST_MODE = true
    
    # Memory profiling configuration
    MEMORY_PROFILER_BACKEND = psutil
    
    # Benchmark configuration
    BENCHMARK_MIN_TIME = 0.000005
    BENCHMARK_MIN_ROUNDS = 5
    BENCHMARK_MAX_TIME = 1.0

commands = 
    # API endpoint performance benchmarking
    pytest tests/integration/performance/ \
        --benchmark-only \
        --benchmark-verbose \
        --benchmark-sort=mean \
        --benchmark-min-time=0.000005 \
        --benchmark-min-rounds=5 \
        --benchmark-max-time=1.0 \
        --benchmark-save=flask_migration_benchmark \
        --benchmark-save-data \
        --benchmark-histogram={toxinidir}/test-results/performance/histograms/ \
        --junit-xml={toxinidir}/test-results/performance/junit.xml \
        --html={toxinidir}/test-results/performance/report.html \
        --self-contained-html \
        {posargs}
    
    # Memory usage profiling
    pytest tests/integration/performance/test_memory_usage.py \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/memory/junit.xml \
        {posargs}

# ===================================================================
# COMPARATIVE TESTING ENVIRONMENT
# ===================================================================

[testenv:py313-comparative]
# Comparative testing between Node.js baseline and Flask implementation
# Ensures 100% functional parity per Section 4.7.2 requirements

description = Node.js vs Flask comparative validation testing

deps = 
    {[testenv]deps}
    # Additional comparative testing dependencies
    deepdiff>=8.0.0
    jsoncompare>=1.0.0
    requests>=2.32.0

setenv = 
    {[testenv]setenv}
    # Comparative testing configuration
    COMPARATIVE_TEST_MODE = true
    NODEJS_BASELINE_URL = http://localhost:3000
    FLASK_TARGET_URL = http://localhost:5000
    
    # Parity validation configuration
    PARITY_THRESHOLD = 0.0
    RESPONSE_TOLERANCE = 0.001
    PERFORMANCE_TOLERANCE = 0.1

commands = 
    # Comprehensive parity validation
    pytest tests/integration/comparative/ \
        --verbose \
        --tb=long \
        --durations=30 \
        --junit-xml={toxinidir}/test-results/comparative/junit.xml \
        --html={toxinidir}/test-results/comparative/report.html \
        --self-contained-html \
        -m "comparative" \
        {posargs}
    
    # API contract compliance validation
    pytest tests/integration/comparative/test_api_parity.py \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/api-parity/junit.xml \
        {posargs}

# ===================================================================
# COVERAGE TESTING ENVIRONMENT
# ===================================================================

[testenv:py313-coverage]
# Comprehensive code coverage analysis for migration validation
# Ensures complete test coverage of Flask implementation

description = Code coverage analysis with pytest-cov

deps = 
    {[testenv]deps}
    coverage[toml]>=7.0.0

setenv = 
    {[testenv]setenv}
    # Coverage configuration
    COVERAGE_PROCESS_START = {toxinidir}/.coveragerc
    COVERAGE_CORE = sysmon

commands = 
    # Run comprehensive test suite with coverage
    coverage erase
    
    pytest tests/integration/ \
        --cov=src \
        --cov-report=html:{toxinidir}/test-results/coverage/html \
        --cov-report=xml:{toxinidir}/test-results/coverage/coverage.xml \
        --cov-report=term-missing \
        --cov-fail-under=95 \
        --cov-branch \
        --junit-xml={toxinidir}/test-results/coverage/junit.xml \
        {posargs}
    
    # Generate coverage reports
    coverage report --show-missing --skip-covered
    coverage html -d {toxinidir}/test-results/coverage/html
    coverage xml -o {toxinidir}/test-results/coverage/coverage.xml

# ===================================================================
# FLASK 3.1.1 COMPATIBILITY TESTING
# ===================================================================

[testenv:py313-flask311]
# Dedicated Flask 3.1.1 compatibility validation environment
# Validates specific Flask version compatibility per Version Compatibility Matrix

description = Flask 3.1.1 specific compatibility validation

deps = 
    # Exact Flask ecosystem versions per technical specification
    Flask==3.1.1
    Flask-SQLAlchemy==3.1.1
    Flask-Migrate==4.1.0
    Werkzeug>=3.1.0
    Jinja2>=3.1.2
    ItsDangerous>=2.2.0
    Click>=8.1.3
    Blinker>=1.9.0
    
    # Testing framework
    pytest-flask==1.3.0
    pytest>=8.0.0,<9.0.0
    pytest-mock>=3.14.0

setenv = 
    {[testenv]setenv}
    # Flask version validation configuration
    FLASK_VERSION_TEST = 3.1.1
    STRICT_VERSION_CHECK = true

commands = 
    # Flask version compatibility validation
    python -c "import flask; print(f'Flask version: {flask.__version__}'); assert flask.__version__ == '3.1.1'"
    
    # Flask ecosystem compatibility testing
    pytest tests/integration/test_flask_version_compatibility.py \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/flask311/junit.xml \
        {posargs}

# ===================================================================
# SQLALCHEMY INTEGRATION TESTING
# ===================================================================

[testenv:py313-sqlalchemy]
# SQLAlchemy integration and database testing environment
# Validates Flask-SQLAlchemy 3.1.1 integration per Section 3.2.2

description = SQLAlchemy integration and database testing

deps = 
    {[testenv]deps}
    # Database testing utilities
    SQLAlchemy>=2.0.0,<3.0.0
    Alembic>=1.13.0

setenv = 
    {[testenv]setenv}
    # Database testing configuration
    SQLALCHEMY_DATABASE_URI = sqlite:///:memory:
    SQLALCHEMY_TRACK_MODIFICATIONS = false
    SQLALCHEMY_ECHO = false

commands = 
    # Database model validation
    pytest tests/integration/database/ \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/sqlalchemy/junit.xml \
        -m "database" \
        {posargs}
    
    # Migration testing
    pytest tests/integration/database/test_migrations.py \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/migrations/junit.xml \
        {posargs}

# ===================================================================
# PARALLEL TESTING ENVIRONMENT
# ===================================================================

[testenv:py313-parallel]
# Parallel test execution environment for comprehensive validation
# Enables distributed testing per Section 4.7.2 requirements

description = Parallel test execution with pytest-xdist

deps = 
    {[testenv]deps}
    pytest-xdist>=3.6.0

setenv = 
    {[testenv]setenv}
    # Parallel execution configuration
    PYTEST_XDIST_WORKER_COUNT = auto

commands = 
    # Parallel integration test execution
    pytest tests/integration/ \
        -n auto \
        --dist=loadscope \
        --verbose \
        --tb=short \
        --junit-xml={toxinidir}/test-results/parallel/junit.xml \
        {posargs}

# ===================================================================
# CODE QUALITY AND LINTING
# ===================================================================

[testenv:lint]
# Code quality validation environment
# Ensures Python code standards and Flask best practices

description = Code quality validation and linting

basepython = python3.13

deps = 
    flake8>=7.0.0
    black>=24.0.0
    isort>=5.13.0
    mypy>=1.8.0
    
    # Flask-specific type checking
    types-Flask>=1.1.0
    types-Werkzeug>=1.0.0

setenv = 
    {[testenv]setenv}

commands = 
    # Code formatting validation
    black --check --diff tests/integration/
    
    # Import sorting validation
    isort --check-only --diff tests/integration/
    
    # Code style validation
    flake8 tests/integration/
    
    # Type checking
    mypy tests/integration/ --ignore-missing-imports

# ===================================================================
# DOCUMENTATION TESTING
# ===================================================================

[testenv:docs]
# Documentation testing and validation environment
# Ensures comprehensive documentation for migration validation

description = Documentation testing and validation

basepython = python3.13

deps = 
    sphinx>=7.0.0
    sphinx-rtd-theme>=2.0.0
    myst-parser>=2.0.0

commands = 
    # Documentation build validation
    sphinx-build -b html docs/ docs/_build/html -W --keep-going
    
    # Documentation link validation
    sphinx-build -b linkcheck docs/ docs/_build/linkcheck

# ===================================================================
# CI/CD INTEGRATION CONFIGURATION
# ===================================================================

[testenv:ci]
# Specialized CI/CD environment for automated pipeline integration
# Optimized for GitHub Actions and automated validation workflows

description = CI/CD pipeline integration environment

deps = 
    {[testenv]deps}

setenv = 
    {[testenv]setenv}
    # CI/CD specific configuration
    CI = true
    GITHUB_ACTIONS = true
    
    # Optimized CI settings
    PYTEST_DISABLE_PLUGIN_AUTOLOAD = true
    PYTEST_TIMEOUT = 300

commands = 
    # Streamlined CI test execution
    pytest tests/integration/ \
        --verbose \
        --tb=short \
        --maxfail=5 \
        --timeout=300 \
        --junit-xml={toxinidir}/test-results/ci/junit.xml \
        --cov=src \
        --cov-report=xml:{toxinidir}/test-results/ci/coverage.xml \
        -m "not slow" \
        {posargs}

# ===================================================================
# TESTING UTILITIES AND HELPERS
# ===================================================================

[testenv:clean]
# Environment cleanup utility
# Removes test artifacts and cached files

description = Clean test artifacts and cache files

deps = 

commands = 
    python -c "
import shutil
import os
import glob

# Clean test results
if os.path.exists('test-results'):
    shutil.rmtree('test-results')

# Clean pytest cache
if os.path.exists('.pytest_cache'):
    shutil.rmtree('.pytest_cache')

# Clean coverage files
for f in glob.glob('.coverage*'):
    if os.path.isfile(f):
        os.remove(f)
    elif os.path.isdir(f):
        shutil.rmtree(f)

# Clean tox cache
if os.path.exists('.tox'):
    print('Note: .tox directory preserved for environment reuse')

print('Test artifacts cleaned successfully')
"

# ===================================================================
# CONFIGURATION VALIDATION
# ===================================================================

[testenv:validate]
# Configuration validation environment
# Validates tox configuration and environment setup

description = Validate tox configuration and environments

deps = 
    tox>=4.26.0

commands = 
    # Validate tox configuration
    tox --help-ini
    
    # List available environments
    tox --listenvs
    
    # Validate environment configuration
    python -c "
import sys
import pkg_resources

print(f'Python version: {sys.version}')
print(f'Platform: {sys.platform}')

# Validate key dependencies
try:
    flask_version = pkg_resources.get_distribution('Flask').version
    print(f'Flask version: {flask_version}')
except:
    print('Flask not installed in current environment')

print('Tox configuration validation complete')
"

# ===================================================================
# DEVELOPMENT CONVENIENCE ENVIRONMENTS
# ===================================================================

[testenv:dev]
# Development environment for interactive testing
# Provides convenient development workflow integration

description = Development environment for interactive testing

deps = 
    {[testenv]deps}
    ipython>=8.0.0
    pdbpp>=0.10.3

setenv = 
    {[testenv]setenv}
    # Development specific configuration
    FLASK_DEBUG = 1
    DEVELOPMENT_MODE = true

commands = 
    # Interactive test execution
    python -c "print('Development environment ready for interactive testing')"
    
    # Available for custom commands
    {posargs:python -c "print('Use: tox -e dev -- <your-command>')"}

# ===================================================================
# ENVIRONMENT-SPECIFIC CONFIGURATION
# ===================================================================

[testenv:quick]
# Quick testing environment for rapid development feedback
# Minimal test suite for fast validation during development

description = Quick test execution for development feedback

deps = 
    {[testenv]deps}

setenv = 
    {[testenv]setenv}

commands = 
    # Quick smoke tests
    pytest tests/integration/test_flask_migration_parity.py::TestFlaskMigrationParity::test_flask_app_initialization \
        --verbose \
        --tb=short \
        {posargs}

# ===================================================================
# SECTION FOOTER AND USAGE NOTES
# ===================================================================

# Usage Examples:
# ===============
# 
# Run all integration tests:
#   tox -e py313-integration
# 
# Run performance benchmarks:
#   tox -e py313-performance
# 
# Run comparative validation:
#   tox -e py313-comparative
# 
# Run with coverage analysis:
#   tox -e py313-coverage
# 
# Run quick development tests:
#   tox -e quick
# 
# Clean all test artifacts:
#   tox -e clean
# 
# Run parallel tests:
#   tox -e py313-parallel
# 
# Validate configuration:
#   tox -e validate
# 
# Run all environments:
#   tox
# 
# Run specific test with custom arguments:
#   tox -e py313-integration -- tests/integration/test_specific.py -v -s
# 
# CI/CD pipeline execution:
#   tox -e ci
#
# Flask version compatibility check:
#   tox -e py313-flask311
#
# This configuration enables comprehensive Flask 3.1.1 migration validation
# with multi-environment testing, performance benchmarking, and automated
# comparison against Node.js baseline systems per technical specification
# Section 4.7.2 requirements.