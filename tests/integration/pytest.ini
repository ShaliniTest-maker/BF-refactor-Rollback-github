# pytest.ini - Integration Testing Configuration for Flask Migration
# Configures pytest-flask plugin, test markers, discovery patterns, and performance testing
# for comprehensive Flask 3.1.1 application integration testing and Node.js parity validation

[tool:pytest]
# Flask Application Testing Configuration
# Configure pytest-flask 1.3.0 plugin for Flask-specific testing capabilities
addopts = 
    # Flask testing configuration
    --strict-markers
    --strict-config
    --disable-warnings
    
    # Coverage and reporting configuration
    --cov=src
    --cov-report=html:tests/integration/htmlcov
    --cov-report=xml:tests/integration/coverage.xml
    --cov-report=term-missing
    --cov-branch
    --cov-fail-under=95
    
    # Test output and formatting
    --verbose
    --tb=short
    --maxfail=10
    --show-capture=no
    
    # Performance testing configuration (pytest-benchmark 5.1.0)
    --benchmark-sort=fullname
    --benchmark-group-by=group
    --benchmark-warmup=on
    --benchmark-warmup-iterations=3
    --benchmark-min-time=0.000005
    --benchmark-autosave
    --benchmark-storage=tests/integration/.benchmarks
    --benchmark-histogram=tests/integration/benchmarks/histograms
    
    # Parallel execution configuration
    -n auto
    --dist=worksteal
    
    # Flask-specific testing options
    --live-server-host=127.0.0.1
    --live-server-port=0

# Test discovery patterns for organized integration test execution
testpaths = 
    tests/integration

# Python file patterns for test discovery
python_files = 
    test_*.py
    *_test.py
    tests.py

# Python class patterns for test discovery
python_classes = 
    Test*
    *Tests
    *Test

# Python function patterns for test discovery
python_functions = 
    test_*
    *_test

# Required plugins for Flask application testing and performance validation
required_plugins = 
    pytest-flask>=1.3.0
    pytest-benchmark>=5.1.0
    pytest-cov>=4.0.0
    pytest-xdist>=3.0.0
    pytest-html>=3.0.0

# Test markers for categorized integration test execution
markers =
    # Core integration test categories
    api: API endpoint integration tests validating Flask blueprint functionality and Node.js parity
    database: Database integration tests for Flask-SQLAlchemy models, transactions, and migration validation
    workflow: Business logic workflow tests ensuring Service Layer pattern functionality and equivalence
    performance: Performance benchmarking tests using pytest-benchmark against Node.js baseline metrics
    comparative: Side-by-side validation tests comparing Node.js and Flask implementation parity
    
    # Specialized test categories
    auth: Authentication and authorization integration tests for Flask decorators and session management
    migration: Database migration and schema validation tests using Flask-Migrate
    contracts: API contract compliance tests ensuring client compatibility and documentation accuracy
    error_handling: Error handling and exception management tests across all Flask components
    
    # Performance subcategories
    load: Concurrent user load testing for scalability validation
    memory: Memory usage profiling and garbage collection performance tests
    query: Database query performance benchmarking with SQLAlchemy optimization
    response_time: API response time validation against SLA requirements
    
    # Environment and infrastructure tests
    e2e: End-to-end workflow tests covering complete system integration
    monitoring: Observability and monitoring integration tests
    security: Security posture validation and penetration testing
    
    # Test execution modifiers
    slow: Tests requiring extended execution time (>30 seconds)
    fast: Quick validation tests for rapid feedback (<5 seconds)
    critical: Critical path tests that must pass for deployment readiness
    regression: Regression tests ensuring no functionality degradation
    
    # Migration validation specific markers
    parity: Functional parity validation between Node.js and Flask implementations
    baseline: Baseline capture and comparison tests for migration validation
    conversion: Direct conversion validation tests for individual component migration

# Minimum Python version requirement
minversion = 6.0

# Test session configuration
console_output_style = progress
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warning filters to reduce noise while maintaining important warnings
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning:distutils.*
    ignore::PendingDeprecationWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    # Flask-specific warning filters
    ignore::flask.warnings.FlaskWarning
    ignore::werkzeug.warnings.WSGIWarning
    # SQLAlchemy warning filters for migration testing
    ignore::sqlalchemy.exc.SAWarning
    ignore::sqlalchemy.exc.RemovedIn20Warning

# Timeout configuration for long-running integration tests
timeout = 300
timeout_method = thread

# Flask application factory configuration for pytest-flask
# These settings ensure proper Flask application initialization for testing
flask_app = src.app:create_app
flask_env = testing

# Database testing configuration
# Ensures proper test database isolation and cleanup
database_uri = sqlite:///:memory:

# Cache configuration for improved test performance
cache_dir = tests/integration/.pytest_cache

# Collection configuration
collect_ignore = [
    "tests/integration/conftest.py",
    "tests/integration/requirements-test.txt",
    "tests/integration/tox.ini",
    "tests/integration/.benchmarks",
    "tests/integration/htmlcov",
    "tests/integration/benchmarks"
]

# Custom test collection behavior
empty_parameter_set_mark = xfail

# JUnit XML configuration for CI/CD integration
junit_suite_name = integration_tests
junit_logging = system-out
junit_log_passing_tests = false
junit_duration_report = total
junit_family = xunit2

# HTML report configuration
htmlpath = tests/integration/reports/integration_test_report.html

# Performance benchmarking configuration for pytest-benchmark 5.1.0
# Baseline comparison settings for Node.js migration validation
benchmark_max_time = 60.0
benchmark_min_rounds = 5
benchmark_timer = time.perf_counter
benchmark_disable_gc = false
benchmark_sort = fullname
benchmark_compare_fail = mean:20%
benchmark_json = tests/integration/benchmarks/benchmark_results.json

# pytest-xdist configuration for parallel test execution
# Optimizes test execution across multiple CPU cores
rsyncdirs = src tests
rsyncignore = *.pyc __pycache__ .git

# Test data configuration
# Paths for test fixtures and sample data
testdata_paths = 
    tests/integration/fixtures
    tests/integration/data

# Flask-SQLAlchemy testing configuration
# Ensures proper database transaction handling during tests
sqlalchemy_database_uri = sqlite:///:memory:
sqlalchemy_track_modifications = false
sqlalchemy_echo = false

# Authentication testing configuration
# Settings for Auth0 and session management testing
auth_testing_mode = true
secret_key = testing-secret-key-for-integration-tests-only
session_cookie_secure = false
session_cookie_httponly = true
session_cookie_samesite = Lax

# Migration testing configuration
# Flask-Migrate settings for database migration testing
migration_directory = migrations
migration_compare_type = true
migration_compare_server_default = true

# Comparative testing configuration
# Settings for Node.js baseline comparison
comparative_testing_enabled = true
nodejs_baseline_url = http://localhost:3000
comparative_timeout = 30.0
parity_tolerance = 0.001

# Performance SLA configuration
# Response time requirements for performance validation
api_response_time_sla = 200  # milliseconds
db_query_time_sla = 100      # milliseconds
auth_response_time_sla = 150 # milliseconds
memory_usage_threshold = 512 # MB

# CI/CD integration configuration
# Settings for automated testing in continuous integration
ci_mode = false
fail_fast = false
capture_output = true
report_generation = true

# Debugging configuration
# Enhanced debugging capabilities for test development
pdb_trace = false
capture_exceptions = true
full_trace = false

# Test environment validation
# Ensures proper test environment setup
validate_flask_app = true
validate_database_connection = true
validate_auth_configuration = true
validate_benchmark_setup = true