[tool:pytest]
# ===========================================
# Pytest Configuration for Flask Application
# ===========================================
# This configuration file defines comprehensive pytest settings for the Flask 3.1.1 
# application testing suite, enabling parallel execution, coverage reporting, 
# performance benchmarking, and test categorization for the Node.js to Python migration.
#
# Key Configuration Areas:
# - Test discovery patterns for Flask application structure
# - Coverage reporting via pytest-cov with HTML output
# - Performance benchmarking integration with pytest-benchmark
# - Custom markers for test categorization (unit, integration, e2e)
# - Flask testing environment configuration
# - Database testing with SQLAlchemy session management

# Test Discovery and Collection
# =============================
# Configure pytest to discover test files following Flask application patterns
# Replaces Node.js test discovery with Python-specific patterns per Section 0.2.1
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test Execution Configuration
# ============================
# Enable parallel test execution for improved performance per Section 3.6.3
addopts = 
    --verbose
    --strict-markers
    --strict-config
    --disable-warnings
    --tb=short
    # Parallel execution using pytest-xdist for improved test performance
    -n auto
    # Coverage reporting with pytest-cov per Section 4.7.3.1
    --cov=app
    --cov=blueprints
    --cov=models
    --cov=services
    --cov=config
    # Coverage reporting configuration with â‰¥95% requirement per Section 4.7.5.1
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-report=xml
    --cov-fail-under=95
    # Performance benchmarking integration per Section 4.7.4.1
    --benchmark-only
    --benchmark-sort=mean
    --benchmark-compare-fail=mean:10%
    --benchmark-histogram=benchmark_histogram

# Flask Testing Environment
# =========================
# Configure Flask-specific testing environment variables
# Ensures proper test isolation and Flask application context per Section 4.7.3.1
env = 
    FLASK_ENV = testing
    FLASK_APP = app.py
    TESTING = True
    WTF_CSRF_ENABLED = False
    # Test database configuration for SQLAlchemy per Section 4.7.3.1
    DATABASE_URL = sqlite:///:memory:
    # Disable external service integrations during testing
    AUTH0_TESTING = True
    DISABLE_AUTH = True

# Custom Test Markers
# ===================
# Define test categorization markers per Section 3.6.3 test classification requirements
# Enables selective test execution and organized test suite management
markers =
    # Unit Test Markers - Individual component testing
    unit: Unit tests for individual functions and classes
    unit_models: Unit tests for SQLAlchemy model definitions and operations
    unit_services: Unit tests for Service Layer business logic components
    unit_blueprints: Unit tests for Flask blueprint route handlers
    unit_auth: Unit tests for authentication and authorization components
    
    # Integration Test Markers - Component interaction testing
    integration: Integration tests for component interactions
    integration_api: Integration tests for API endpoint functionality
    integration_database: Integration tests for database operations and transactions
    integration_auth: Integration tests for authentication flow validation
    integration_services: Integration tests for Service Layer orchestration
    
    # End-to-End Test Markers - Full workflow testing
    e2e: End-to-end tests for complete user workflows
    e2e_api: End-to-end API contract validation tests
    e2e_auth: End-to-end authentication and authorization workflows
    e2e_data: End-to-end data processing and persistence workflows
    
    # Performance Test Markers - SLA and benchmark validation
    performance: Performance benchmarking tests per Section 4.7.4.1
    benchmark: Pytest-benchmark performance validation tests
    load: Load testing and scalability validation tests
    sla: Service Level Agreement compliance validation tests
    
    # Specialized Test Markers
    slow: Tests that take longer than 1 second to execute
    external: Tests requiring external service dependencies
    database: Tests requiring database connectivity and transactions
    auth: Tests involving authentication and authorization logic
    migration: Tests validating Node.js to Flask migration parity
    
    # CI/CD and Quality Gate Markers
    smoke: Smoke tests for basic functionality validation
    regression: Regression tests for preventing functionality degradation
    security: Security validation and vulnerability tests
    compatibility: Cross-platform and version compatibility tests

# Test Timeout Configuration
# ==========================
# Configure test execution timeouts to prevent hanging tests
# Ensures reliable CI/CD pipeline execution per Section 4.7.5.2
timeout = 300
timeout_method = thread

# Logging Configuration
# ====================
# Configure pytest logging for comprehensive test execution visibility
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test output control for detailed reporting
log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s() %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Performance Benchmarking Configuration
# ======================================
# Configure pytest-benchmark for Node.js baseline comparison per Section 4.7.4.1
# Statistical performance analysis with regression detection and SLA validation
benchmark-warmup = 3
benchmark-warmup-iterations = 5
benchmark-min-rounds = 10
benchmark-max-time = 30
benchmark-timer = time.perf_counter
benchmark-calibration-precision = 10
benchmark-storage = file://benchmark_storage.json
benchmark-histogram = true

# Database Testing Configuration
# ==============================
# Configure database testing with transaction isolation per Section 4.7.3.1
# Ensures clean test state and prevents test interdependencies
database_isolation = transaction
database_transaction_rollback = true

# Warning Filters
# ===============
# Filter expected warnings to reduce noise in test output
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:sqlalchemy.*
    ignore::pytest.PytestUnraisableExceptionWarning

# Pytest Plugin Configuration
# ===========================
# Required plugins for comprehensive Flask application testing per Section 3.6.3
required_plugins =
    pytest-flask>=1.3.0
    pytest-cov>=4.0.0
    pytest-xdist>=3.3.0
    pytest-benchmark>=4.0.0
    pytest-mock>=3.11.0
    pytest-timeout>=2.1.0

# Flask Testing Specific Configuration
# ===================================
# Configure Flask test client and application context management
# Supports pytest-flask plugin integration per Section 4.7.3.1
flask_app = app:create_app
flask_config = testing

# Test Data and Fixture Configuration
# ===================================
# Configure test data management and Factory Boy integration per Section 4.7.3.2
# Supports comprehensive test fixture management
fixtures_dir = tests/fixtures
factory_boy_session = function

# Cache Configuration
# ==================
# Configure pytest caching for improved test execution performance
cache_dir = tests/.pytest_cache