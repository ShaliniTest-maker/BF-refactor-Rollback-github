[tool:pytest]
# ==================================================================================
# Pytest Configuration for Flask 3.1.1 Migration Testing
# ==================================================================================
# This configuration file defines comprehensive testing framework settings for
# the Node.js to Flask 3.1.1 migration project. It configures Pytest 8.3.3 with
# Flask testing utilities, coverage reporting, and performance benchmarking to
# ensure 100% functional parity validation between systems.
#
# Configured according to Section 3.6.3 Testing Framework and Section 4.7 Testing
# and Validation Workflow requirements from the technical specification.
# ==================================================================================

# ==================================================================================
# Core Pytest Configuration
# ==================================================================================
# Minimum Pytest version requirement per Section 3.6.3
minversion = 8.3.3

# Test discovery patterns for Flask application structure
# Organized to match Flask blueprint-based modular architecture
testpaths = 
    tests
    tests/unit
    tests/integration
    tests/end_to_end
    tests/performance

# Test file naming patterns
# Supports comprehensive test discovery across Flask application modules
python_files = 
    test_*.py
    *_test.py
    tests.py

# Test function naming patterns
python_functions = 
    test_*
    *_test

# Test class naming patterns
python_classes = 
    Test*
    *Tests

# ==================================================================================
# Flask Testing Integration (Section 3.6.3)
# ==================================================================================
# Flask application fixtures and test client configuration
# Enables Flask test client initialization and database session management
addopts = 
    --verbose
    --strict-markers
    --strict-config
    --tb=short
    --disable-warnings
    --color=yes
    --durations=10
    --maxfail=5

# Required for Flask testing utilities and pytest-flask plugin integration
required_plugins = 
    pytest-flask>=1.3.0
    pytest-cov>=6.0.0
    pytest-benchmark>=5.1.0
    pytest-xdist>=3.8.0
    pytest-mock>=3.14.0

# ==================================================================================
# Coverage Reporting Configuration (Section 4.7.5)
# ==================================================================================
# Comprehensive coverage analysis with â‰¥95% coverage requirement
# Configured per Section 4.7.5 Quality Assurance Checkpoints
addopts = 
    --cov=.
    --cov-config=pytest.ini
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=term-missing
    --cov-report=annotate
    --cov-fail-under=95

# Coverage source paths
[coverage:run]
source = .
branch = true
omit = 
    */venv/*
    */virtualenv/*
    */.env/*
    */migrations/*
    */tests/*
    */__pycache__/*
    */htmlcov/*
    setup.py
    wsgi.py
    config.py

# Coverage reporting configuration
[coverage:report]
precision = 2
show_missing = true
skip_covered = false
exclude_lines = 
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

# Coverage HTML report configuration
[coverage:html]
directory = htmlcov
title = Flask Migration Test Coverage Report

# Coverage XML report configuration
[coverage:xml]
output = coverage.xml

# ==================================================================================
# Test Markers Configuration (Section 4.7.3)
# ==================================================================================
# Test categorization for systematic validation approach
# Enables targeted test execution and quality gate validation
markers = 
    unit: Unit tests for individual components and functions
    integration: Integration tests for API endpoints and service interactions
    end_to_end: End-to-end tests for complete workflow validation
    performance: Performance benchmarking tests with pytest-benchmark
    database: Tests requiring database connections and transactions
    auth: Authentication and authorization tests
    api: API endpoint tests with Flask test client
    service: Service layer tests for business logic validation
    model: SQLAlchemy model tests for database operations
    blueprint: Flask blueprint routing tests
    migration: Database migration and schema validation tests
    slow: Long-running tests that may be skipped in quick validation
    mock: Tests using mock objects and external service simulation
    security: Security validation and vulnerability tests
    parity: Functional parity validation against Node.js baseline
    benchmark: Performance benchmarking against baseline metrics

# ==================================================================================
# Flask Testing Configuration
# ==================================================================================
# Flask-specific testing configuration
# Database testing with SQLAlchemy session management per Section 3.6.3
FLASK_ENV = testing
TESTING = true

# Test database configuration
# Isolated test database to prevent data corruption during test execution
SQLALCHEMY_DATABASE_URI = sqlite:///:memory:
SQLALCHEMY_TRACK_MODIFICATIONS = false
SQLALCHEMY_ECHO = false

# ==================================================================================
# Parallel Test Execution (Section 3.6.3)
# ==================================================================================
# pytest-xdist configuration for concurrent test execution
# Optimized for CI/CD pipeline performance and development productivity
addopts = 
    --numprocesses=auto
    --dist=loadfile

# ==================================================================================
# Performance Benchmarking Configuration (Section 4.7.4)
# ==================================================================================
# pytest-benchmark integration for SLA validation and regression detection
# Statistical performance analysis with baseline comparison capabilities
[tool:pytest-benchmark]
# Performance test configuration
min_rounds = 5
max_time = 2.0
min_time = 0.1
warmup = true
warmup_iterations = 3
disable_gc = true
timer = time.perf_counter

# Benchmark output configuration
sort = min
columns = min,max,mean,stddev,median,iqr,outliers,ops,rounds
histogram = true
json = benchmarks.json
compare_fail = mean:5% stddev:10%

# ==================================================================================
# Mock and Fixture Configuration
# ==================================================================================
# pytest-mock integration for external service testing
# Factory Boy and test data management configuration
mock_use_standalone_module = true

# Fixture scope configuration for test isolation
# Ensures proper setup and teardown for database and Flask application context
pytest_plugins = 
    pytest_flask
    pytest_benchmark
    pytest_mock

# ==================================================================================
# Logging Configuration for Test Execution
# ==================================================================================
# Structured logging during test execution for debugging and analysis
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Log file configuration
log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# ==================================================================================
# Test Environment Isolation
# ==================================================================================
# Environment variable management for test execution
# Prevents test interference with development and production environments
env = 
    FLASK_ENV = testing
    TESTING = true
    WTF_CSRF_ENABLED = false
    SECRET_KEY = test-secret-key-not-for-production
    DATABASE_URL = sqlite:///:memory:

# ==================================================================================
# Quality Gate Enforcement
# ==================================================================================
# Automated quality validation per Section 4.7.5 Quality Assurance Checkpoints
# Enforces comprehensive testing standards and SLA compliance
filterwarnings = 
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:werkzeug.*
    error::pytest.PytestUnraisableExceptionWarning

# Test timeout configuration
timeout = 300
timeout_method = thread

# ==================================================================================
# Test Data and Factory Configuration
# ==================================================================================
# Factory Boy integration for test data generation
# Supports realistic test data patterns with relationship management
# Per Section 4.7.3.2 Test Data Management requirements
factoryboy_file = tests/factories.py

# Test database seeding and cleanup configuration
# Ensures consistent test environment state between execution cycles
setup_show = true
setup_plan = true

# ==================================================================================
# Docker and CI/CD Integration
# ==================================================================================
# Configuration for containerized testing environments
# Supports pytest execution in Docker containers and CI/CD pipelines
docker = true
ci = true

# Exit codes configuration for CI/CD pipeline integration
# Ensures proper test result communication to deployment systems
addopts = 
    --tb=line
    --maxfail=1
    --ff

# ==================================================================================
# Migration-Specific Testing Configuration
# ==================================================================================
# Specialized configuration for Node.js to Flask migration validation
# Supports dual-stack comparison testing and functional parity validation
# Per Section 4.7.1 Functionality Parity Validation Process

# Parity testing configuration
parity_baseline_url = http://localhost:3000
parity_flask_url = http://localhost:5000
parity_test_timeout = 30

# Performance comparison configuration
performance_baseline_file = tests/data/nodejs_baseline_metrics.json
performance_tolerance_percent = 5

# Migration validation markers
migration_markers = 
    parity_critical: Critical functionality requiring 100% parity validation
    parity_performance: Performance benchmarking against Node.js baseline
    parity_api: API contract validation between systems
    parity_data: Data operation consistency validation
    parity_auth: Authentication behavior validation

# ==================================================================================
# End of Configuration
# ==================================================================================